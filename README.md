ğŸ›¡ï¸ Phishing Susceptibility Detection System

Sistema de detecciÃ³n de susceptibilidad a phishing basado en factores humanos, entrenado con Gradient Boosting, desplegado en Databricks Model Serving e integrado con Streamlit y Evidently AI para monitoreo.

ğŸ“ Arquitectura General
Google Colab
  â””â”€â”€ Entrenamiento del modelo (MLflow)
        â””â”€â”€ Registro en Databricks (Unity Catalog)
              â””â”€â”€ Databricks Model Serving (Endpoint REST)
                    â””â”€â”€ Streamlit App (PredicciÃ³n en tiempo real)
                          â””â”€â”€ Evidently AI (Drift & Monitoring)

ğŸ” Flujo de ActualizaciÃ³n del Modelo (ALTA IMPORTANCIA)

Cuando se entrena un nuevo modelo, NO se crea un nuevo endpoint.
Se actualiza la versiÃ³n del modelo servido.

1ï¸âƒ£ Entrenamiento del Modelo (Google Colab)

El entrenamiento se realiza en Google Colab, usando mlflow conectado a Databricks.

Requisitos

Token de Databricks

URI del Workspace

MLflow configurado con Unity Catalog

import mlflow
mlflow.set_registry_uri("databricks-uc")


El modelo se registra siempre con el mismo nombre:

registered_model_name = "workspace.default.phishing_detector_tree"


ğŸ“Œ Importante
Cada entrenamiento crea una nueva versiÃ³n:

v1, v2, v3, ...

2ï¸âƒ£ Verificar la Nueva VersiÃ³n en Databricks

En Databricks Workspace:

Ir a Models

Buscar phishing_detector_tree

Verificar:

Nueva versiÃ³n creada

MÃ©tricas correctas

Signature definida (obligatorio)

âš ï¸ Databricks exige signature (input + output).

3ï¸âƒ£ Actualizar el Modelo en Serving (PASO CRÃTICO)
NO crear un endpoint nuevo âŒ
Actualizar el modelo servido en el endpoint existente âœ…
ğŸ”§ Pasos en Databricks UI

Ir a Serving

Seleccionar el endpoint (ej: api_phishing)

Click en Edit / Update configuration

En Served Models:

Cambiar la versiÃ³n del modelo
Ejemplo:

phishing_detector_tree : v3


Guardar cambios

â³ El endpoint se reinicia automÃ¡ticamente.

4ï¸âƒ£ Verificar el Endpoint
Endpoint URL
https://<DATABRICKS-HOST>/serving-endpoints/api_phishing/invocations

Headers requeridos
Authorization: Bearer <DATABRICKS_TOKEN>
Content-Type: application/json

Payload esperado
{
  "dataframe_records": [
    {
      "Fatiga_Global_Score": 1.8,
      "Big5_Responsabilidad": 3.9,
      "Big5_Apertura": 4.1,
      "Demo_Generacion_Edad": 3,
      "Demo_Rol_Trabajo": 2,
      "Demo_Horas": 4
    }
  ]
}

5ï¸âƒ£ Cambios en Streamlit (Si aplica)

âš ï¸ Normalmente NO es necesario cambiar nada si:

Las features se mantienen

El schema del modelo no cambia

Solo revisar si:

Se agregan nuevas variables

Se cambia el orden / nombre de columnas

6ï¸âƒ£ Logging de Predicciones (ProducciÃ³n)

Las predicciones se almacenan localmente en:

production_predictions.csv


Cada registro contiene:

Timestamp

Features de entrada

PredicciÃ³n del modelo

Este archivo se utiliza para:

Evidently AI

AnÃ¡lisis de drift

AuditorÃ­a de decisiones

7ï¸âƒ£ Evidently AI (Monitoreo)

El monitoreo se ejecuta desde la app Streamlit.

Baseline requerido

Archivo:

training_baseline.csv


UbicaciÃ³n recomendada:

/data/training_baseline.csv


Este archivo contiene:

Features del dataset de entrenamiento

Sin la variable objetivo

GeneraciÃ³n del Reporte

Desde la pÃ¡gina de resultados:

Click en ğŸ“ˆ Generar reporte de monitoreo

Se genera:

evidently_phishing_report.html


Se renderiza directamente en la app

ğŸ“Œ Nota:
El anÃ¡lisis de clasificaciÃ³n (accuracy, recall, etc.) NO se ejecuta si no existe target real en producciÃ³n.

âš ï¸ Consideraciones Importantes de Databricks
Community / No Full Version

âŒ No hay Inference Tables

âŒ No hay Auto-logging en Serving

âŒ No hay Jobs programados

Por eso:

El logging se hace desde la app

Evidently corre localmente

Errores Comunes
Error	Causa
ENDPOINT_NOT_FOUND	URL incorrecta
Model has no signature	Modelo registrado sin signature
ConnectionClosedError	Red pÃºblica / firewall
probability = null	Modelo no expone predict_proba
ğŸ“Œ Buenas PrÃ¡cticas

âœ” Mantener el mismo nombre de modelo
âœ” Versionar solo el modelo, no el endpoint
âœ” No entrenar en Databricks si no es necesario
âœ” Usar Evidently para drift, no para accuracy en prod
âœ” Documentar cada cambio de versiÃ³n

ğŸ“„ Archivos Clave del Repositorio
â”œâ”€â”€ app.py
â”œâ”€â”€ pages/
â”‚   â””â”€â”€ results.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ databricks.py
â”‚   â”œâ”€â”€ scoring.py
â”‚   â””â”€â”€ logging.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ training_baseline.csv
â”œâ”€â”€ production_predictions.csv
â””â”€â”€ README.md

ğŸ‘¤ Autor

Proyecto acadÃ©mico / aplicado en ciberseguridad y factores humanos.
Enfocado en prevenciÃ³n, concientizaciÃ³n y riesgo humano.
